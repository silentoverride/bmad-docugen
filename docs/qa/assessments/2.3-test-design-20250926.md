# Test Design: Story 2.3

Date: 2025-09-26
Designer: Quinn (Test Architect)

## Test Strategy Overview

- Total test scenarios: 10
- Unit tests: 3 (30.0%)
- Integration tests: 6 (60.0%)
- E2E tests: 1 (10.0%)
- Priority distribution: P0: 8, P1: 2, P2: 0

## Test Scenarios by Acceptance Criteria

### AC1: Automated visual diff compares generated PDFs against golden fixtures with â‰¥95% similarity threshold and stored diff artefacts on failure.

#### Scenarios

| ID           | Level       | Priority | Test                                                                                             | Justification                                                                                         |
| ------------ | ----------- | -------- | ------------------------------------------------------------------------------------------------ | ----------------------------------------------------------------------------------------------------- |
| 2.3-UNIT-001 | Unit        | P0       | Validate diff threshold configuration and template-specific tolerances                           | Keeps diff engine deterministic and tuned, mitigating TECH-009.                                       |
| 2.3-INT-001  | Integration | P0       | Generate intentional template regression and confirm diff artefacts stored with 95% threshold enforcement | Confirms diff pipeline catches real regressions and persists evidence.                               |
| 2.3-INT-002  | Integration | P0       | Cross-environment diff comparison (CI vs local) verifying golden fixtures remain consistent      | Detects baseline drift before it reaches production.                                                  |

### AC2: Reconciliation step validates totals, dates, and identifiers across artefacts prior to packaging, halting runs on inconsistencies.

#### Scenarios

| ID           | Level       | Priority | Test                                                                                       | Justification                                                                                                  |
| ------------ | ----------- | -------- | ------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------- |
| 2.3-UNIT-002 | Unit        | P0       | Reconciliation validator enforces totals, dates, and identifier matching with tolerance rules | Pure logic; critical to prevent false negatives highlighted in DATA-009.                                        |
| 2.3-INT-003  | Integration | P0       | Inject mismatched totals to confirm run halts and emits diagnostics prior to packaging        | Validates gating behaviour across CLI/worker boundary.                                                          |
| 2.3-INT-004  | Integration | P1       | Re-run reconciliation after manual correction to ensure green path proceeds                  | Medium risk ensures override/resolution loops restore pipeline.                                                |

### AC3: CLI surfaces pass/fail summary with links to diff reports and reconciliation logs.

#### Scenarios

| ID           | Level       | Priority | Test                                                                                           | Justification                                                                                           |
| ------------ | ----------- | -------- | ---------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------- |
| 2.3-INT-005  | Integration | P0       | CLI output includes diff links, reconciliation logs, and exit codes for pass/fail states       | Ensures operator experience aligns with remediation workflows.                                        |
| 2.3-E2E-001  | E2E         | P0       | Full CLI run capturing diff failure scenario verifies user-facing guidance and manifest linkage | Confirms cross-surface UX expectations and evidence generation.                                       |

### AC4: CI pipeline publishes fidelity metrics to monitoring dashboards for historical tracking.

#### Scenarios

| ID           | Level       | Priority | Test                                                                                              | Justification                                                                                                 |
| ------------ | ----------- | -------- | ------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------- |
| 2.3-UNIT-003 | Unit        | P1       | Metrics exporter formats fidelity data with manifest IDs and template references                  | Lower risk but ensures consistent labeling for observability.                                                 |
| 2.3-INT-006  | Integration | P0       | CI job publishes metrics and artefacts; dashboards ingest diff pass rate and runtime statistics   | Critical to ensure fidelity telemetry appears for monitoring and gating (OPS-008/PERF-005 mitigation).        |
| 2.3-INT-007  | Integration | P0       | Trigger CI failure path to ensure diff artefacts retained and accessible via manifest references | Verifies storage retention and observability interplay for regression debugging.                             |

## Risk Coverage

- TECH-009 addressed via diff threshold, regression, and cross-environment validations.
- DATA-009 mitigated with reconciliation logic tests and halt verification.
- OPS-008/PERF-005 covered through artefact retention and CI telemetry scenarios.

## Recommended Execution Order

1. P0 unit tests (2.3-UNIT-001, 2.3-UNIT-002)
2. P0 integration tests (2.3-INT-001, 2.3-INT-002, 2.3-INT-003, 2.3-INT-005, 2.3-INT-006, 2.3-INT-007)
3. P0 E2E test (2.3-E2E-001)
4. P1 tests (2.3-INT-004, 2.3-UNIT-003)

## Quality Checklist

- [x] Every AC has test coverage
- [x] Test levels are appropriate (not over-testing)
- [x] No duplicate coverage across levels
- [x] Priorities align with business risk
- [x] Test IDs follow naming convention
- [x] Scenarios are atomic and independent
