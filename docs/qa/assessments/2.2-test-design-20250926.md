# Test Design: Story 2.2

Date: 2025-09-26
Designer: Quinn (Test Architect)

## Test Strategy Overview

- Total test scenarios: 9
- Unit tests: 3 (33.3%)
- Integration tests: 5 (55.6%)
- E2E tests: 1 (11.1%)
- Priority distribution: P0: 7, P1: 2, P2: 0

## Test Scenarios by Acceptance Criteria

### AC1: Google Places integration retrieves legal name, suburb, and ABN-like metadata, storing responses in encrypted cache with configurable TTL.

#### Scenarios

| ID           | Level       | Priority | Test                                                                                              | Justification                                                                                                     |
| ------------ | ----------- | -------- | ------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------- |
| 2.2-UNIT-001 | Unit        | P0       | Normalize Google Places response (field ordering, null handling) before cache storage              | Ensures deterministic and clean data representation critical for downstream manifests.                             |
| 2.2-UNIT-002 | Unit        | P0       | Validate cache TTL and encryption configuration parsing                                           | Guards configuration drift that could expose sensitive data or break determinism.                                  |
| 2.2-INT-001  | Integration | P0       | Invoke enrichment client with live stub ensuring encrypted cache write and deterministic key usage | Critical boundary test verifying encryption-at-rest and deterministic caching behaviour.                           |
| 2.2-INT-002  | Integration | P1       | Refresh entry before TTL expiry to confirm cache hit and encryption reuse                         | Medium risk scenario ensuring pipelines avoid unnecessary API calls.                                             |

### AC2: Offline fallback dataset covers top 100 Australian merchant categories relevant to lending use cases.

#### Scenarios

| ID           | Level       | Priority | Test                                                                                              | Justification                                                                                              |
| ------------ | ----------- | -------- | ------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------- |
| 2.2-UNIT-003 | Unit        | P0       | Validate fallback dataset schema, category coverage, and deterministic seeding alignment           | Keeps fixtures authoritative and mitigates stale data risk.                                                 |
| 2.2-INT-003  | Integration | P0       | Force offline mode and confirm fallback dataset produces deterministic enrichment results          | Ensures deterministic output when network unavailable, aligning with critical risk DATA-008.               |

### AC3: Cache miss, fallback use, and enrichment overrides are logged in manifests for audit replay.

#### Scenarios

| ID           | Level       | Priority | Test                                                                                           | Justification                                                                                               |
| ------------ | ----------- | -------- | ---------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------- |
| 2.2-INT-004  | Integration | P0       | Execute enrichment run using live cache hit, miss, and override to validate manifest log entries | Critical for audit traceability; ensures logs capture pathway details.                                     |
| 2.2-E2E-001  | E2E         | P0       | Full CLI run with override scenario confirms manifest diagnostics, cache telemetry, and CLI output | Confirms cross-surface traceability for compliance review.                                                  |

### AC4: Integration tests simulate quota exhaustion and offline modes to confirm deterministic outputs.

#### Scenarios

| ID           | Level       | Priority | Test                                                                                                  | Justification                                                                                               |
| ------------ | ----------- | -------- | ----------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------- |
| 2.2-INT-005  | Integration | P0       | Simulate quota exhaustion returning partial responses, verify fallback activation and deterministic output | Directly mitigates critical risk DATA-008 by ensuring fallback path consistency.                             |
| 2.2-INT-006  | Integration | P1       | Chaos test toggling between online/offline modes mid-run, confirm final artefacts remain stable          | Medium risk stress scenario verifying resilience to state transitions.                                     |

## Risk Coverage

- DATA-008 addressed via normalization, offline enforcement, and quota exhaustion simulations.
- SEC-006 mitigated through encryption tests and manifest logging checks.
- OPS-007 covered by fallback dataset schema validation and offline integration tests.

## Recommended Execution Order

1. P0 unit tests (2.2-UNIT-001, 2.2-UNIT-002, 2.2-UNIT-003)
2. P0 integration tests (2.2-INT-001, 2.2-INT-003, 2.2-INT-004, 2.2-INT-005)
3. P0 E2E test (2.2-E2E-001)
4. P1 integration tests (2.2-INT-002, 2.2-INT-006)

## Quality Checklist

- [x] Every AC has test coverage
- [x] Test levels are appropriate (not over-testing)
- [x] No duplicate coverage across levels
- [x] Priorities align with business risk
- [x] Test IDs follow naming convention
- [x] Scenarios are atomic and independent
